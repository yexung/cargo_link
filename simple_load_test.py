#!/usr/bin/env python3
import requests
import time
import threading
from concurrent.futures import ThreadPoolExecutor

# í…ŒìŠ¤íŠ¸ ì„¤ì •
BASE_URL = "http://localhost:3000"
CONCURRENT_USERS = 60
REQUESTS_PER_USER = 3

# í†µê³„
stats = {
    'total_requests': 0,
    'successful_requests': 0,
    'failed_requests': 0,
    'response_times': [],
    'errors': []
}
stats_lock = threading.Lock()

def update_stats(success, response_time, status_code=None, error=None):
    with stats_lock:
        stats['total_requests'] += 1
        if success:
            stats['successful_requests'] += 1
        else:
            stats['failed_requests'] += 1
            if error:
                stats['errors'].append(f"{status_code}: {str(error)}")
        stats['response_times'].append(response_time)

def make_request(url):
    """ë‹¨ì¼ ìš”ì²­ ìˆ˜í–‰"""
    start_time = time.time()
    try:
        response = requests.get(url, timeout=5)
        response_time = time.time() - start_time
        success = response.status_code < 400
        update_stats(success, response_time, response.status_code)
        return response.status_code, response_time
    except Exception as e:
        response_time = time.time() - start_time
        update_stats(False, response_time, 0, e)
        return 0, response_time

def user_simulation(user_id):
    """ê°œë³„ ì‚¬ìš©ì ì‹œë®¬ë ˆì´ì…˜"""
    urls = [
        BASE_URL,
        f"{BASE_URL}/admin_users/sign_in",
        f"{BASE_URL}/vehicles"
    ]
    
    for _ in range(REQUESTS_PER_USER):
        for url in urls:
            make_request(url)

def run_load_test():
    """ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print(f"ğŸš€ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹œì‘: {CONCURRENT_USERS}ëª… ë™ì‹œ ì‚¬ìš©ì, ê°ê° {REQUESTS_PER_USER * 3}ê°œ ìš”ì²­")
    print(f"ğŸ“Š ì´ ì˜ˆìƒ ìš”ì²­ ìˆ˜: {CONCURRENT_USERS * REQUESTS_PER_USER * 3}")
    
    start_time = time.time()
    
    # ThreadPoolExecutor ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ì‹¤í–‰
    with ThreadPoolExecutor(max_workers=CONCURRENT_USERS) as executor:
        futures = []
        for user_id in range(CONCURRENT_USERS):
            future = executor.submit(user_simulation, user_id)
            futures.append(future)
        
        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        for future in futures:
            future.result()
    
    end_time = time.time()
    total_time = end_time - start_time
    
    # ê²°ê³¼ ë¶„ì„
    print(f"\nğŸ“ˆ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
    print(f"ğŸ“ ì´ ìš”ì²­ ìˆ˜: {stats['total_requests']}")
    print(f"âœ… ì„±ê³µ: {stats['successful_requests']} ({stats['successful_requests']/stats['total_requests']*100:.1f}%)")
    print(f"âŒ ì‹¤íŒ¨: {stats['failed_requests']} ({stats['failed_requests']/stats['total_requests']*100:.1f}%)")
    
    if stats['response_times']:
        avg_response_time = sum(stats['response_times']) / len(stats['response_times'])
        max_response_time = max(stats['response_times'])
        min_response_time = min(stats['response_times'])
        
        print(f"âš¡ í‰ê·  ì‘ë‹µì‹œê°„: {avg_response_time:.3f}ì´ˆ")
        print(f"ğŸ”¥ ìµœëŒ€ ì‘ë‹µì‹œê°„: {max_response_time:.3f}ì´ˆ")
        print(f"âš¡ ìµœì†Œ ì‘ë‹µì‹œê°„: {min_response_time:.3f}ì´ˆ")
        
        if total_time > 0:
            rps = stats['total_requests'] / total_time
            print(f"ğŸš€ ì´ˆë‹¹ ì²˜ë¦¬ ìš”ì²­ ìˆ˜ (RPS): {rps:.1f}")
            
            # ë™ì‹œ ì ‘ì†ì ì¶”ì •
            estimated_concurrent_users = int(rps * avg_response_time)
            print(f"ğŸ‘¥ ì˜ˆìƒ ìµœëŒ€ ë™ì‹œ ì ‘ì†ì: {estimated_concurrent_users}ëª…")
    
    if stats['errors']:
        print(f"\nğŸš¨ ì£¼ìš” ì—ëŸ¬:")
        error_counts = {}
        for error in stats['errors']:
            error_counts[error] = error_counts.get(error, 0) + 1
        for error, count in sorted(error_counts.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"   {error}: {count}íšŒ")

if __name__ == "__main__":
    run_load_test()